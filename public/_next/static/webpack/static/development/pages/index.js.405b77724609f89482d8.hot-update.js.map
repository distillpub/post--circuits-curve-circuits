{"version":3,"file":"static/webpack/static/development/pages/index.js.405b77724609f89482d8.hot-update.js","sources":["webpack:///./pages/article.md"],"sourcesContent":["\nimport React from 'react'\nimport { mdx } from '@mdx-js/react'\n\n/* @jsx mdx */\nimport Neuron from 'components/neuron'\nimport H2 from 'components/h2'\nimport H3 from 'components/h3'\nimport Sidebar from 'pages/sidebar'\nimport PrevNext from 'components/prevNext'\nimport Colab from 'components/colab'\nimport CurvesFeatureVis from './curvesFeatureVis'\nimport Curve1 from './simplified/curve1'\nimport simplifiedActivations from './data/simplified-activations.json'\nimport Curve2 from './simplified/curve2'\nimport CurveDataset from './simplified/dataset'\nimport Exponential from './dataset/exponential'\nimport DatasetQuilt from './dataset/quilt'\nimport AttributionSample from './dataset/attributionSample'\nimport HumanLabels from './dataset/humanLabels'\nimport FalsePositives from './dataset/falsePositives'\nimport Tuning from './tuning'\nimport SyntheticIntro from './synthetic/intro'\nimport SyntheticMain from './synthetic/main'\nimport SyntheticCosmetic from './synthetic/cosmetic'\nimport Angle1 from './synthetic/angle/angle1'\nimport AngleZoomIn from './synthetic/angle/angleZoomIn'\nimport ToCurves from './synthetic/angle/toCurves'\nimport Radial from './radial'\nimport FamiliesModel from './curveFamilies/model'\nimport RadialLayer from './curveFamilies/radialLayer'\nimport Highlight4a406 from './curveFamilies/4a406'\nimport Extraction from './curveAnalysis/extraction'\nimport DiffParams from './curveAnalysis/diffParam'\nimport Tracing from './curveAnalysis/tracing'\nimport Butterfly from './curveAnalysis/butterfly'\nimport ButterflyQuilt from './curveAnalysis/butterflyQuilt'\nimport CombingEffect from './combing'\nimport CombingDataset from './combing/dataset'\n\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  \n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n    <Sidebar mdxType=\"Sidebar\" />\n    <div>\n      <PrevNext mdxType=\"PrevNext\" />\n      <p>Every vision model we've explored in detail contains neurons which detect curves. Curve detectors in vision models have been hinted at in the literature as far back as 2013 (see figures in Zeiler & Fergus <d-cite bibtex-key='zeiler2014visualizing'></d-cite>), and similar neurons have been studied carefully in neuroscience <d-cite bibtex-key=\"tang2018complex\"></d-cite>. We  <a href=\"https://distill.pub/2020/circuits/early-vision/#group_mixed3b_curves\">briefly discussed</a> curve in our earlier overview of early vision, but wanted to examine them in more depth. This article is the first part of a three article deep dive into curve detectors: their behavior, how they’re built from earlier neurons, and their prevalence across models.</p>\n      <p>We’re doing this because we believe that the interpretability community disagrees on several crucial questions. In particular, are neural network representations composed of meaningful features — that is, features tracking articulable properties of images? On the one hand, there are a number of papers reporting on seemingly meaningful features, such as eye detectors, head detectors, car detectors, and so forth <d-cite bibtex-key=\"mikolov2013distributed,karpathy2015visualizing,radford2017learning,zhou2014object,olah2017feature,netdissect2017\"></d-cite>. At the same time, there’s a significant amount of skepticism, only partially reflected in the literature. One concern is that features which seem superficially to be meaningful may in fact not be what they appear <d-cite bibtex-key=\"donnelly2019interpretability\"></d-cite>. Several papers have suggested that neural networks primarily detect textures or imperceptible patterns<d-cite bibtex-key=\"jo2017measuring,geirhos2018imagenet,brendel2019approximating,ilyas2019adversarial\"></d-cite> rather than the kind of meaningful features described earlier. Finally, even if some meaningful features exist, it’s possible they don’t play an especially important role in the network<d-cite bibtex-key=\"morcos2018importance\"></d-cite>.  Some reconcile these results by concluding that if one observes, for example, what appears to be a dog head detector, it is actually a detector for special textures correlated with dog heads.</p>\n      <p>This disagreement really matters. If every neuron was meaningful, and their connections formed meaningful circuits, we believe it would open a path to completely reverse engineering and interpreting neural networks. Of course, we know not every neuron is meaningful, <d-footnote>As discussed in Zoom In, the main issue we see is what we call polysemantic neurons which respond to multiple different features, seemingly as a way to compress many features into a smaller number of neurons. We're hopeful this can be worked around.</d-footnote> but we think it's close enough for this path to be tractable. However, our position is definitely not the consensus view. Moreover, it seems too good to be true, and rings of the similar failed promises in other fields<d-footnote>For example, genetics seems to have been optimistic in the past that genes had individual functions and that the human genome project would allow us to “mine miracles,\" a position which now seems to be regarded as having been naive.</d-footnote> — skepticism is definitely warranted!</p>\n      <p>We believe that curve detectors are a good vehicle for making progress on this disagreement. Curve detectors seem like a modest step from edge-detecting Gabor filters, which the community widely agrees often form in the first convolutional layer. Artificial curves are simple to generate, opening up lots of possibilities for rigorous investigation. And the fact that they're only a couple convolutional layers deep means we can follow every string of neurons back to the input. At the same time, the underlying algorithm the model has implemented for curve detection is quite sophisticated. If this paper persuades skeptics that at least curve detectors exist, that seems like a substantial step forward. Similarly, if it surfaces a more precise point of disagreement, that would also advance the dialogue.</p>\n    </div>\n    <H2 mdxType=\"H2\">A Simplified Story of Curve Neurons</H2>\n    <p>{`Let's look at a simplified story of the 10 curve detectors in 3b. `}</p>\n\n    <CurvesFeatureVis mdxType=\"CurvesFeatureVis\" />\n    <p>{`Each curve detector implements a variant of the same algorithm, detecting curves in different orientations. It responds to a wide variety of curves, preferring curves in a given orientation, and gradually firing less as the orientation changes. They are invariant to cosmetic properties such as brightness and color. `}</p>\n\n\n    <Curve1 data={simplifiedActivations} mdxType=\"Curve1\" />\n    <p>{`Curve detectors collectively span all orientations.`}</p>\n\n    <Curve2 data={simplifiedActivations} mdxType=\"Curve2\" />\n    <p><strong parentName=\"p\">{`Curve`}</strong>{` detectors have sparse activations, responding to only 10% of spatial positions  `}<d-footnote>{`Receptive-field sized crops of an image.`}</d-footnote>{` across ImageNet. Even in the cases where they fire, the vast majority of stimuli cause them to fire only slightly. They are most excited by curves with a similar orientation and curvature to the neuron's feature visualization.`}</p>\n\n    <CurveDataset mdxType=\"CurveDataset\" />\n    <p>{`Since curves are useful for building sophisticated shapes like circles and 3d geometry, nearly all convolutional neural networks trained on natural images have families of curve neurons.`}</p>\n    <hr />\n    <p>{`It's worth stepping back and reflecting on how surprising the existence of seemingly meaningful features like curve detectors is. There's no explicit incentive for the network to form meaningful neurons. It's not like we optimized those neurons to be curve detectors! Rather, InceptionV1 is trained to classify images into categories many levels of abstraction removed from curves and somehow curve detectors fell out of the gradient descent process.`}</p>\n    <p>{`Moreover, detecting curves across a wide variety of natural images is a difficult and arguably unsolved problem in classical computer vision`}<d-footnote>{`This is our sense from trying to implement curve detection traditional techniques to compare them to curve neurons. We generally found that programmers looking to detect curves in practice had to choose between a variety of algorithms with significant trade-offs such as robustness to different kinds of visual noise, even in images much less noisy than those found in ImageNet. For instance, `}<a href=\"https://stackoverflow.com/questions/8260338/detecting-curves-in-opencv\">{`an answer on StackOverflow`}</a>{` claims “The problem `}{`[of curve detection]`}{`, in general, is a very challenging one and, except for toy examples, there are no good solutions.\" Additionally, many of these algorithms are too slow to run in real time, or have high memory costs.`}</d-footnote>{`. Our network seems to have learned a quite flexible and general solution to this problem, implemented over five convolutional layers. We'll see in the next article that the algorithm used is straightforward and understandable, and we've since reimplemented it by hand.`}</p>\n    <p>{`What are we claiming exactly when we say these neurons detect curves? We think that part of the reason why there can be disagreement about whether features detect a given property is that there's a variety of claims one might be making. It's pretty easy to show that, empirically, when curve detectors fire strongly the stimuli are reliably curves. But there are several other claims which might be more contentious:`}</p>\n    <ul>\n      <li parentName=\"ul\">\n        <p parentName=\"li\"><strong parentName=\"p\">{`Causality`}</strong>{` Curve detectors genuinely detect a curve feature, rather than another feature correlated with curves. We believe our feature visualization and visualizing attribution experiments establish a causal link, since “running it in reverse\" produces a curve. `}</p>\n      </li>\n      <li parentName=\"ul\">\n        <p parentName=\"li\"><strong parentName=\"p\">{`Generality:`}</strong>{` Curve detectors respond to a wide variety of curve stimuli. They tolerate a wide range of radii and are more sensitive to orientation. They're largely invariant to cosmetic attributes like color, brightness, and texture.`}</p>\n      </li>\n      <li parentName=\"ul\">\n        <p parentName=\"li\"><strong parentName=\"p\">{`Purity:`}</strong>{` Curve detectors are not polysemantic and they have no meaningful secondary function. Images that cause curve detectors to activate weakly, such as edges or angles, are natural continuous extensions of curve detection.`}</p>\n      </li>\n      <li parentName=\"ul\">\n        <p parentName=\"li\"><strong parentName=\"p\">{`Family:`}</strong>{` Curve neurons collectively span all orientations of curves.`}</p>\n      </li>\n    </ul>\n    <H2 mdxType=\"H2\">Feature Visualization</H2>\n    <p><a href=\"https://distill.pub/2017/feature-visualization/\">Feature visualization</a><d-cite bibtex-key=\"erhan2009visualizing,olah2017feature,simonyan2013deep,nguyen2015deep,mordvintsev2015inceptionism,nguyen2016plug\"></d-cite> uses optimization to find the input to a neural network that maximizes an objective. The objective we use most often is making a neuron fire as strongly as possible, but we'll also use other objectives in this article. One reason feature visualization is powerful is that it's causal. Since the input starts with random noise and optimizes over pixels rather than a generative prior, we can be confident that any property in the resulting image caused contributed to the objective.</p>\n    <CurvesFeatureVis mdxType=\"CurvesFeatureVis\" />\n    <p>{`Reading feature visualizations is a bit of a skill, and these images might feel disorienting if you haven't spent much time with them before. The most important thing to take away is the curve shape. You may also notice that there are bright, opposite hue colors on each side of the curve: this reflects a preference to see a chance in color at the boundary of the curve. Finally, if you look carefully, you will notice small lines perpendicular to the boundary of the curve. We call this weak preference for small perpendicular lines “combing\" and will discuss it later. `}</p>\n    <p>{`Using feature visualization to make curve detectors fire as strongly as possible reliably creates images of curves, even when run with different seeds or a `}<a href=\"https://distill.pub/2017/feature-visualization/#diversity\" target=\"_blank\">{`diversity term`}</a>{` that is optimized to create multiple images that differ from each other. This is evidence that curve detectors aren't polysemantic in the sense of equally preferring very different types of inputs.`}</p>\n    <p>{`Feature visualization shows us stimuli that maximally cause a neuron to fire, but are they representative of the neuron's general behavior? When we see a feature visualization, we often imagine that the neuron fires strongly for stimuli qualitatively similar to it, and gradually stops firing as the stimuli exhibit that property less. But one could also imagine cases where the neuron's behavior is completely different in the non-extreme activations, or cases where it does fire weakly for messy versions of the extreme stimulus, but also has a secondary class of stimulus to which it responds weakly.`}</p>\n    <p>{`If we want to understand how a neuron behaves in practice, there's no substitute to simply looking at how it actually responds to a natural distribution of stimuli.`}</p>\n    <H2 mdxType=\"H2\">Dataset Examples</H2>\n    <p>{`Our studies of the dataset will focus on `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` because we will do some experiments that required non-trivial manual labor, but the core ideas apply to all curve detectors in 3b.`}</p>\n    <p>{`A natural first question is to ask what the distribution of activations is like. How often does `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` fire? When it fires, how often does it fire strongly? And when it doesn't fire, is it often strongly inhibited, or just on the verge of firing?`}</p>\n    <p>{`When analyzing ReLU networks, we often look at the distribution of pre-activation values in answering these questions. Since ReLU just truncates the left hand side, it's easy to reason about the post activation values, but it also makes it easy for us to understand how close the neuron is to firing in other cases.`}<d-footnote>{`Looking at pre-activation values also avoids the distribution having a dirac delta peak at zero.`}</d-footnote>{` We find that `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` pre-activation distribution with a mean near -200. We also find that it fires in just 11% of cases across the dataset, since activations below 0 will be set to zero by the activation function.`}</p>\n    <p>{`To better understand the distribution of activations, we find it helpful to look at a log plot of the probability. This reveals that in the activating regime, activations are distributed as an exponential distribution corresponding to a straight line in the plot.`}<d-footnote>{`The observation that neural network activations generally follow an exponential distribution was first made to us by Brice Ménard, who observed it to be the case over all but the first layer of several networks. This is mildly surprising both because of how perfectly they seem to follow an exponential distribution, and also because one often expects linear combinations of random variables to form a Gaussian. `}</d-footnote>{` One consequence of this is that, since probability density decays at `}<d-math>{`e^{-x}`}</d-math>{` rather than `}<d-math>{`e^{-x^2}`}</d-math>{` of a Gaussian, we should expect the distribution to have long tails.`}</p>\n\n    <Exponential mdxType=\"Exponential\" />\n    <p>{`We can also view a quilt of images by activations by randomly sampling from grouped values of activations to get a qualitative sense of what kinds of images cause `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` to activate different amounts. They follow a pattern. Images that cause the strongest activations all have curves that are similar to the neuron's feature visualization. Weakly activating images are imperfect curves `}{`—`}{` too flat, off-orientation, or off in another way. Activations near zero tend to be straight lines or images with no arcs, although some contain curves about 45 degrees off orientation. Finally, the images that cause the strongest negative activations have curves with an orientation more than 45 degrees away from the neuron's ideal curve.`}</p>\n\n    <DatasetQuilt mdxType=\"DatasetQuilt\" />\n    <p>{`Quilts of images are useful for seeing patterns across a wide range of activations, but they have the potential to be misleading. A neuron's activation to a receptive-field size crop gives us just a single number, and we could be misled by spurious correlations in the images. For instance, since many of the images that cause `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` to fire most strongly are clocks, we may think the neuron detects clocks, rather than curves. `}</p>\n    <p>{`To see `}<em parentName=\"p\">{`why`}</em>{` an image excites a neuron, we must understand the image's attribution to the neuron.`}</p>\n    <H2 mdxType=\"H2\">Visualizing Attribution</H2>\n    <p>{`Almost all the tools we use for studying neuron families, including feature visualization, can be used in context of a particular image using attribution. `}</p>\n    <p>{`There is a significant amount of work on how to do attribution in neural networks (eg. `}<d-cite bibtex-key=\"sundararajan2017axiomatic,selvaraju2016grad,kindermans2017patternnet\"></d-cite>{`). These methods attempt to describe which inputs or previous neurons are responsible for the firing of later neurons. In the general case of complex nonlinear functions, there is a lot of disagreement about which attribution methods are principled and whether they are reliable `}<d-cite bibtex-key=\"kindermans2017reliability,adebayo2018sanity\"></d-cite>{`. But attribution is generally agreed on for the linear case, with most methods collapsing to the same answer. If we are considering a single neuron, it's pre-activation value is a linear function of neurons in the previous layer. The result is that a neuron in the previous layer influences a given neuron by its value times the weight between them. We call the tensor describing how all neurons in the previous layer influenced a given neuron the attribution tensor of that neuron.`}</p>\n    <p>{`We normally apply feature visualization to create a stimulus that activates a single neuron, but we can also use it to activate any combination of neurons. By applying feature visualization to the attribution tensor, we can visualize which features at the previous layer caused a neuron to fire. We can further apply feature visualization to the absolute value of the attribution tensor, to see both features that caused the neuron to fire and also features that inhibited it. `}</p>\n    <p>{`Combining this together gives us `}<span parentName=\"p\" {...{\n        \"className\": \"math math-inline\"\n      }}><span parentName=\"span\" {...{\n          \"className\": \"katex\"\n        }}><span parentName=\"span\" {...{\n            \"className\": \"katex-mathml\"\n          }}><math parentName=\"span\" {...{\n              \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n            }}><semantics parentName=\"math\"><mrow parentName=\"semantics\"><mtext parentName=\"mrow\">{`FeatureVisualization`}</mtext><mo parentName=\"mrow\" {...{\n                    \"stretchy\": \"false\"\n                  }}>{`(`}</mo><mtext parentName=\"mrow\">{`abs`}</mtext><mo parentName=\"mrow\" {...{\n                    \"stretchy\": \"false\"\n                  }}>{`(`}</mo><mi parentName=\"mrow\">{`W`}</mi><mo parentName=\"mrow\">{`⊙`}</mo><msub parentName=\"mrow\"><mi parentName=\"msub\">{`h`}</mi><mrow parentName=\"msub\"><mi parentName=\"mrow\">{`p`}</mi><mi parentName=\"mrow\">{`r`}</mi><mi parentName=\"mrow\">{`e`}</mi><mi parentName=\"mrow\">{`v`}</mi></mrow></msub><mo parentName=\"mrow\" {...{\n                    \"stretchy\": \"false\"\n                  }}>{`)`}</mo><mo parentName=\"mrow\" {...{\n                    \"stretchy\": \"false\"\n                  }}>{`)`}</mo></mrow><annotation parentName=\"semantics\" {...{\n                  \"encoding\": \"application/x-tex\"\n                }}>{`\\\\text{FeatureVisualization}(\\\\text{abs}(W \\\\odot h_{prev}))`}</annotation></semantics></math></span><span parentName=\"span\" {...{\n            \"className\": \"katex-html\",\n            \"aria-hidden\": \"true\"\n          }}><span parentName=\"span\" {...{\n              \"className\": \"base\"\n            }}><span parentName=\"span\" {...{\n                \"className\": \"strut\",\n                \"style\": {\n                  \"height\": \"1em\",\n                  \"verticalAlign\": \"-0.25em\"\n                }\n              }}></span><span parentName=\"span\" {...{\n                \"className\": \"mord text\"\n              }}><span parentName=\"span\" {...{\n                  \"className\": \"mord\"\n                }}>{`FeatureVisualization`}</span></span><span parentName=\"span\" {...{\n                \"className\": \"mopen\"\n              }}>{`(`}</span><span parentName=\"span\" {...{\n                \"className\": \"mord text\"\n              }}><span parentName=\"span\" {...{\n                  \"className\": \"mord\"\n                }}>{`abs`}</span></span><span parentName=\"span\" {...{\n                \"className\": \"mopen\"\n              }}>{`(`}</span><span parentName=\"span\" {...{\n                \"className\": \"mord mathdefault\",\n                \"style\": {\n                  \"marginRight\": \"0.13889em\"\n                }\n              }}>{`W`}</span><span parentName=\"span\" {...{\n                \"className\": \"mspace\",\n                \"style\": {\n                  \"marginRight\": \"0.2222222222222222em\"\n                }\n              }}></span><span parentName=\"span\" {...{\n                \"className\": \"mbin\"\n              }}>{`⊙`}</span><span parentName=\"span\" {...{\n                \"className\": \"mspace\",\n                \"style\": {\n                  \"marginRight\": \"0.2222222222222222em\"\n                }\n              }}></span></span><span parentName=\"span\" {...{\n              \"className\": \"base\"\n            }}><span parentName=\"span\" {...{\n                \"className\": \"strut\",\n                \"style\": {\n                  \"height\": \"1.036108em\",\n                  \"verticalAlign\": \"-0.286108em\"\n                }\n              }}></span><span parentName=\"span\" {...{\n                \"className\": \"mord\"\n              }}><span parentName=\"span\" {...{\n                  \"className\": \"mord mathdefault\"\n                }}>{`h`}</span><span parentName=\"span\" {...{\n                  \"className\": \"msupsub\"\n                }}><span parentName=\"span\" {...{\n                    \"className\": \"vlist-t vlist-t2\"\n                  }}><span parentName=\"span\" {...{\n                      \"className\": \"vlist-r\"\n                    }}><span parentName=\"span\" {...{\n                        \"className\": \"vlist\",\n                        \"style\": {\n                          \"height\": \"0.15139200000000003em\"\n                        }\n                      }}><span parentName=\"span\" {...{\n                          \"style\": {\n                            \"top\": \"-2.5500000000000003em\",\n                            \"marginLeft\": \"0em\",\n                            \"marginRight\": \"0.05em\"\n                          }\n                        }}><span parentName=\"span\" {...{\n                            \"className\": \"pstrut\",\n                            \"style\": {\n                              \"height\": \"2.7em\"\n                            }\n                          }}></span><span parentName=\"span\" {...{\n                            \"className\": \"sizing reset-size6 size3 mtight\"\n                          }}><span parentName=\"span\" {...{\n                              \"className\": \"mord mtight\"\n                            }}><span parentName=\"span\" {...{\n                                \"className\": \"mord mathdefault mtight\"\n                              }}>{`p`}</span><span parentName=\"span\" {...{\n                                \"className\": \"mord mathdefault mtight\",\n                                \"style\": {\n                                  \"marginRight\": \"0.02778em\"\n                                }\n                              }}>{`r`}</span><span parentName=\"span\" {...{\n                                \"className\": \"mord mathdefault mtight\"\n                              }}>{`e`}</span><span parentName=\"span\" {...{\n                                \"className\": \"mord mathdefault mtight\",\n                                \"style\": {\n                                  \"marginRight\": \"0.03588em\"\n                                }\n                              }}>{`v`}</span></span></span></span></span><span parentName=\"span\" {...{\n                        \"className\": \"vlist-s\"\n                      }}>{`​`}</span></span><span parentName=\"span\" {...{\n                      \"className\": \"vlist-r\"\n                    }}><span parentName=\"span\" {...{\n                        \"className\": \"vlist\",\n                        \"style\": {\n                          \"height\": \"0.286108em\"\n                        }\n                      }}><span parentName=\"span\"></span></span></span></span></span></span><span parentName=\"span\" {...{\n                \"className\": \"mclose\"\n              }}>{`)`}</span><span parentName=\"span\" {...{\n                \"className\": \"mclose\"\n              }}>{`)`}</span></span></span></span></span>{`, where `}<span parentName=\"p\" {...{\n        \"className\": \"math math-inline\"\n      }}><span parentName=\"span\" {...{\n          \"className\": \"katex\"\n        }}><span parentName=\"span\" {...{\n            \"className\": \"katex-mathml\"\n          }}><math parentName=\"span\" {...{\n              \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n            }}><semantics parentName=\"math\"><mrow parentName=\"semantics\"><mi parentName=\"mrow\">{`W`}</mi></mrow><annotation parentName=\"semantics\" {...{\n                  \"encoding\": \"application/x-tex\"\n                }}>{`W`}</annotation></semantics></math></span><span parentName=\"span\" {...{\n            \"className\": \"katex-html\",\n            \"aria-hidden\": \"true\"\n          }}><span parentName=\"span\" {...{\n              \"className\": \"base\"\n            }}><span parentName=\"span\" {...{\n                \"className\": \"strut\",\n                \"style\": {\n                  \"height\": \"0.68333em\",\n                  \"verticalAlign\": \"0em\"\n                }\n              }}></span><span parentName=\"span\" {...{\n                \"className\": \"mord mathdefault\",\n                \"style\": {\n                  \"marginRight\": \"0.13889em\"\n                }\n              }}>{`W`}</span></span></span></span></span>{` is the weights for a given neuron, and `}<span parentName=\"p\" {...{\n        \"className\": \"math math-inline\"\n      }}><span parentName=\"span\" {...{\n          \"className\": \"katex\"\n        }}><span parentName=\"span\" {...{\n            \"className\": \"katex-mathml\"\n          }}><math parentName=\"span\" {...{\n              \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n            }}><semantics parentName=\"math\"><mrow parentName=\"semantics\"><msub parentName=\"mrow\"><mi parentName=\"msub\">{`h`}</mi><mi parentName=\"msub\">{`p`}</mi></msub><mi parentName=\"mrow\">{`r`}</mi><mi parentName=\"mrow\">{`e`}</mi><mi parentName=\"mrow\">{`v`}</mi></mrow><annotation parentName=\"semantics\" {...{\n                  \"encoding\": \"application/x-tex\"\n                }}>{`h_prev`}</annotation></semantics></math></span><span parentName=\"span\" {...{\n            \"className\": \"katex-html\",\n            \"aria-hidden\": \"true\"\n          }}><span parentName=\"span\" {...{\n              \"className\": \"base\"\n            }}><span parentName=\"span\" {...{\n                \"className\": \"strut\",\n                \"style\": {\n                  \"height\": \"0.980548em\",\n                  \"verticalAlign\": \"-0.286108em\"\n                }\n              }}></span><span parentName=\"span\" {...{\n                \"className\": \"mord\"\n              }}><span parentName=\"span\" {...{\n                  \"className\": \"mord mathdefault\"\n                }}>{`h`}</span><span parentName=\"span\" {...{\n                  \"className\": \"msupsub\"\n                }}><span parentName=\"span\" {...{\n                    \"className\": \"vlist-t vlist-t2\"\n                  }}><span parentName=\"span\" {...{\n                      \"className\": \"vlist-r\"\n                    }}><span parentName=\"span\" {...{\n                        \"className\": \"vlist\",\n                        \"style\": {\n                          \"height\": \"0.15139200000000003em\"\n                        }\n                      }}><span parentName=\"span\" {...{\n                          \"style\": {\n                            \"top\": \"-2.5500000000000003em\",\n                            \"marginLeft\": \"0em\",\n                            \"marginRight\": \"0.05em\"\n                          }\n                        }}><span parentName=\"span\" {...{\n                            \"className\": \"pstrut\",\n                            \"style\": {\n                              \"height\": \"2.7em\"\n                            }\n                          }}></span><span parentName=\"span\" {...{\n                            \"className\": \"sizing reset-size6 size3 mtight\"\n                          }}><span parentName=\"span\" {...{\n                              \"className\": \"mord mathdefault mtight\"\n                            }}>{`p`}</span></span></span></span><span parentName=\"span\" {...{\n                        \"className\": \"vlist-s\"\n                      }}>{`​`}</span></span><span parentName=\"span\" {...{\n                      \"className\": \"vlist-r\"\n                    }}><span parentName=\"span\" {...{\n                        \"className\": \"vlist\",\n                        \"style\": {\n                          \"height\": \"0.286108em\"\n                        }\n                      }}><span parentName=\"span\"></span></span></span></span></span></span><span parentName=\"span\" {...{\n                \"className\": \"mord mathdefault\",\n                \"style\": {\n                  \"marginRight\": \"0.02778em\"\n                }\n              }}>{`r`}</span><span parentName=\"span\" {...{\n                \"className\": \"mord mathdefault\"\n              }}>{`e`}</span><span parentName=\"span\" {...{\n                \"className\": \"mord mathdefault\",\n                \"style\": {\n                  \"marginRight\": \"0.03588em\"\n                }\n              }}>{`v`}</span></span></span></span></span>{` is the activations of the previous hidden layer. In practice, we find it helpful to parameterize these attribution visualizations to be grayscale and transparent, making the visualization easier to read for non-experts `}<d-cite bibtex-key=\"mordvintsev2018differentiable\"></d-cite>{`. Example code can be found in the notebook.`}</p>\n\n    <AttributionSample mdxType=\"AttributionSample\" />\n    <p>{`We can also use attribution to revisit the dataset examples we saw before in more depth, seeing why each image caused `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` to fire. You can click the figure to toggle between seeing raw images and attribution vector feature visualizations.`}</p>\n    <DatasetQuilt isAttrs mdxType=\"DatasetQuilt\" />\n    <p>{`Attribution is a powerful technique for studying circuits in the context of an image or set of images. While the above experiment visualizes every neuron in the previous layer, we could study an image in more depth, visualizing its activation and activation vector as it flows through the families into `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{`. Each activation vector would show us what a family saw in the image, and each attribution vector would show us how that family contributed to activating `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{`.`}</p>\n    <p>{`In the next section we'll look at a less sophisticated technique for extracting information from dataset images: blindfolding yourself from seeing neuron activations and classifying images by hand.`}</p>\n    <H2 mdxType=\"H2\">Comparison to Humans</H2>\n    <p>{`Nick Cammarata, an author of this paper, manually labelled over 800 images into four groups: curve, imperfect curve, unrelated image, or opposing curve. To construct the dataset he would label, we randomly sampled a fixed number of images from ImageNet's training grouped by `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{`  activations in bins of 100`}<d-footnote>{`The data in this paper is from our first sampling of images.`}</d-footnote>{`. During the labeling process Nick could only see each image's pixels, and was blinded to the neuron's activation or attribution visualizations. He used the following rubric in assigning labels:`}</p>\n    <ul>\n      <li parentName=\"ul\">\n        <p parentName=\"li\"><strong parentName=\"p\">{`Curves`}</strong>{`: Images are curves with a similar orientation to the neuron's feature visualization. The curve goes across most of the width of the image.`}</p>\n      </li>\n      <li parentName=\"ul\">\n        <p parentName=\"li\"><strong parentName=\"p\">{`Imperfect Curve`}</strong>{`: The curve has similarities to the neuron's feature visualization, but it is not quite right. Perhaps it is too flat, has an angle interrupting the arc, or the orientation is slightly off. `}</p>\n      </li>\n      <li parentName=\"ul\">\n        <p parentName=\"li\"><strong parentName=\"p\">{`Unrelated`}</strong>{`: The image doesn't have a curve.`}</p>\n      </li>\n      <li parentName=\"ul\">\n        <p parentName=\"li\"><strong parentName=\"p\">{`Opposing Curve`}</strong>{`: The image contains curves but they are in a very different orientation than the neuron's feature visualization.`}</p>\n      </li>\n    </ul>\n    <p>{`After constructing this dataset of hand-labelled images, we compared the labels to the image's neuron activations.`}</p>\n\n    <HumanLabels active=\"stackData\" yAxisProps={{\n      label: \"Proportion of Labels\"\n    }} caption=\"Conditional probability of each group by 3b:379 activation across our hand-labelled dataset of around 850 images.\" data={require('./data/human-firstplot.json')} mdxType=\"HumanLabels\" />\n    <p>{`One interesting aspect of this chart is how clearly separated the groups are. Throughout labelling, Nick felt it was often difficult to place samples cleanly into groups, as many seemed to fall between the boundaries, and he began to believe the task has inherent noise. We were surprised when we saw that activations fell naturally into different levels of activation.`}</p>\n    <p>{`Still, there are many images that cause the neuron to activate but aren't classified as curves or imperfect curves. When we visualize attribution to `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` we see that many of the images contain subtle curves. `}</p>\n\n    <FalsePositives mdxType=\"FalsePositives\" />\n    <p>{`Nick found it hard to detect subtle curves across hundreds of curve images because he was aware of the `}<a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Afterimage\">{`Afterimage effect`}</a>{`.  that occurs when looking at one type of stimulus for too long. Visualizing attribution vectors reveals the curves the neuron sees in the image, and can even make it easier for us to see the curves ourselves when we may have originally missed it. In these cases `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` is a superhuman curve detector.`}</p>\n    <p><strong parentName=\"p\">{`How important are different points on the activation spectrum?`}</strong></p>\n    <p>{`These charts are helpful for comparing our hand-labelled groups but they give an incomplete picture. While `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` seems to be highly selective for curve stimuli when it fires strongly, these are only tiny fraction of cases where it fires. Most of the time, it doesn't fire at all, and when it does the most common case is for it to fire only very weakly.`}</p>\n    <p>{`To see this, we can look at the probability density over activation magnitudes from all ImageNet examples, split into the same per-activation-magnitude (x-axis) ratio of classes as our hand labelled dataset.`}</p>\n    <HumanLabels active=\"probability\" probChart yAxisProps={{\n      label: \"Probability Density\"\n    }} caption=\"While our hand-labelled dataset uniformly samples from activations, images of curves are rare within the dataset and 3b:379 activations follow an exponential distribution. In this plot we show 3b:379 activations split into the conditional probabilities of different groups at a given activation level within our hand-labelled dataset.\" data={require('./data/human-probabilities.json')} mdxType=\"HumanLabels\" />\n    <p>{`From this perspective, we can't even see the cases where our neuron fires strongly! Probability density exponentially decays as we move right, and so achieving these activations is rare. To some extent, this is what we should expect if these units really are curve detectors: clear cut curves are a rare occurrence in images.`}</p>\n    <p>{`Perhaps more concerning is that, although curves are a small fraction of the cases where `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` only weakly fired or didn't fire, it appears from this graph that the majority of stimuli classified as curves also fall in these cases, as a result of neurons firing strongly being many orders of magnitude rarer. This seems to be at least partly due to labeling error and the rarity of curves (see discussion later). But it makes things a bit hard to reason about. This is why we haven't provided a precision-recall curve: recall would be dominated by the cases where the neuron didn't fire strongly and be dominated by potential labeling error as a result.`}</p>\n    <p>{`It's not clear that probability density is really the right way to think about the behavior of a neuron. The vast majority of cases are cases where the neuron didn't fire: are those actually important to think about? And if a neuron frequently barely fires, how important is that for understanding the role of a neuron in the network?`}</p>\n    <p>{`An alternative measure for thinking about the importance of different parts of the activation spectrum is  `}<em parentName=\"p\">{`contribution to expected value`}</em>{`, `}<span parentName=\"p\" {...{\n        \"className\": \"math math-inline\"\n      }}><span parentName=\"span\" {...{\n          \"className\": \"katex\"\n        }}><span parentName=\"span\" {...{\n            \"className\": \"katex-mathml\"\n          }}><math parentName=\"span\" {...{\n              \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n            }}><semantics parentName=\"math\"><mrow parentName=\"semantics\"><mi parentName=\"mrow\">{`x`}</mi><mo parentName=\"mrow\">{`∗`}</mo><mi parentName=\"mrow\">{`p`}</mi><mo parentName=\"mrow\" {...{\n                    \"stretchy\": \"false\"\n                  }}>{`(`}</mo><mi parentName=\"mrow\">{`x`}</mi><mo parentName=\"mrow\" {...{\n                    \"stretchy\": \"false\"\n                  }}>{`)`}</mo></mrow><annotation parentName=\"semantics\" {...{\n                  \"encoding\": \"application/x-tex\"\n                }}>{`x*p(x)`}</annotation></semantics></math></span><span parentName=\"span\" {...{\n            \"className\": \"katex-html\",\n            \"aria-hidden\": \"true\"\n          }}><span parentName=\"span\" {...{\n              \"className\": \"base\"\n            }}><span parentName=\"span\" {...{\n                \"className\": \"strut\",\n                \"style\": {\n                  \"height\": \"0.46528em\",\n                  \"verticalAlign\": \"0em\"\n                }\n              }}></span><span parentName=\"span\" {...{\n                \"className\": \"mord mathdefault\"\n              }}>{`x`}</span><span parentName=\"span\" {...{\n                \"className\": \"mspace\",\n                \"style\": {\n                  \"marginRight\": \"0.2222222222222222em\"\n                }\n              }}></span><span parentName=\"span\" {...{\n                \"className\": \"mbin\"\n              }}>{`∗`}</span><span parentName=\"span\" {...{\n                \"className\": \"mspace\",\n                \"style\": {\n                  \"marginRight\": \"0.2222222222222222em\"\n                }\n              }}></span></span><span parentName=\"span\" {...{\n              \"className\": \"base\"\n            }}><span parentName=\"span\" {...{\n                \"className\": \"strut\",\n                \"style\": {\n                  \"height\": \"1em\",\n                  \"verticalAlign\": \"-0.25em\"\n                }\n              }}></span><span parentName=\"span\" {...{\n                \"className\": \"mord mathdefault\"\n              }}>{`p`}</span><span parentName=\"span\" {...{\n                \"className\": \"mopen\"\n              }}>{`(`}</span><span parentName=\"span\" {...{\n                \"className\": \"mord mathdefault\"\n              }}>{`x`}</span><span parentName=\"span\" {...{\n                \"className\": \"mclose\"\n              }}>{`)`}</span></span></span></span></span>{`. This measure can be thought of as giving an approximation at how much that activation value influences the output of the neuron, and by extension network behavior. There's still reason to think that high activation cases may be disproportionately important beyond this (for example, in max pooling only the highest value matters), but contribution to expected value seems like a reasonable estimate.`}<d-footnote>{`If one wanted to push further on exploring the importance of different parts of the activation spectrum, they might take some notion of attribution (methods for estimating the influence of one neuron on later neurons in a particular case) and estimate the contribution to the expected value of the attribution to the logit. A simple version of this would be to look at `}<span parentName=\"p\" {...{\n          \"className\": \"math math-inline\"\n        }}><span parentName=\"span\" {...{\n            \"className\": \"katex\"\n          }}><span parentName=\"span\" {...{\n              \"className\": \"katex-mathml\"\n            }}><math parentName=\"span\" {...{\n                \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n              }}><semantics parentName=\"math\"><mrow parentName=\"semantics\"><mi parentName=\"mrow\">{`x`}</mi><mo parentName=\"mrow\">{`∗`}</mo><mfrac parentName=\"mrow\"><mrow parentName=\"mfrac\"><mi parentName=\"mrow\">{`d`}</mi><mtext parentName=\"mrow\">{`logit`}</mtext></mrow><mrow parentName=\"mfrac\"><mi parentName=\"mrow\">{`d`}</mi><mi parentName=\"mrow\">{`x`}</mi></mrow></mfrac><mo parentName=\"mrow\">{`∗`}</mo><mi parentName=\"mrow\">{`p`}</mi><mo parentName=\"mrow\" {...{\n                      \"stretchy\": \"false\"\n                    }}>{`(`}</mo><mi parentName=\"mrow\">{`x`}</mi><mo parentName=\"mrow\" {...{\n                      \"stretchy\": \"false\"\n                    }}>{`)`}</mo></mrow><annotation parentName=\"semantics\" {...{\n                    \"encoding\": \"application/x-tex\"\n                  }}>{`x*\\\\frac{d\\\\text{logit}}{dx}*p(x)`}</annotation></semantics></math></span><span parentName=\"span\" {...{\n              \"className\": \"katex-html\",\n              \"aria-hidden\": \"true\"\n            }}><span parentName=\"span\" {...{\n                \"className\": \"base\"\n              }}><span parentName=\"span\" {...{\n                  \"className\": \"strut\",\n                  \"style\": {\n                    \"height\": \"0.46528em\",\n                    \"verticalAlign\": \"0em\"\n                  }\n                }}></span><span parentName=\"span\" {...{\n                  \"className\": \"mord mathdefault\"\n                }}>{`x`}</span><span parentName=\"span\" {...{\n                  \"className\": \"mspace\",\n                  \"style\": {\n                    \"marginRight\": \"0.2222222222222222em\"\n                  }\n                }}></span><span parentName=\"span\" {...{\n                  \"className\": \"mbin\"\n                }}>{`∗`}</span><span parentName=\"span\" {...{\n                  \"className\": \"mspace\",\n                  \"style\": {\n                    \"marginRight\": \"0.2222222222222222em\"\n                  }\n                }}></span></span><span parentName=\"span\" {...{\n                \"className\": \"base\"\n              }}><span parentName=\"span\" {...{\n                  \"className\": \"strut\",\n                  \"style\": {\n                    \"height\": \"1.277216em\",\n                    \"verticalAlign\": \"-0.345em\"\n                  }\n                }}></span><span parentName=\"span\" {...{\n                  \"className\": \"mord\"\n                }}><span parentName=\"span\" {...{\n                    \"className\": \"mopen nulldelimiter\"\n                  }}></span><span parentName=\"span\" {...{\n                    \"className\": \"mfrac\"\n                  }}><span parentName=\"span\" {...{\n                      \"className\": \"vlist-t vlist-t2\"\n                    }}><span parentName=\"span\" {...{\n                        \"className\": \"vlist-r\"\n                      }}><span parentName=\"span\" {...{\n                          \"className\": \"vlist\",\n                          \"style\": {\n                            \"height\": \"0.9322159999999999em\"\n                          }\n                        }}><span parentName=\"span\" {...{\n                            \"style\": {\n                              \"top\": \"-2.6550000000000002em\"\n                            }\n                          }}><span parentName=\"span\" {...{\n                              \"className\": \"pstrut\",\n                              \"style\": {\n                                \"height\": \"3em\"\n                              }\n                            }}></span><span parentName=\"span\" {...{\n                              \"className\": \"sizing reset-size6 size3 mtight\"\n                            }}><span parentName=\"span\" {...{\n                                \"className\": \"mord mtight\"\n                              }}><span parentName=\"span\" {...{\n                                  \"className\": \"mord mathdefault mtight\"\n                                }}>{`d`}</span><span parentName=\"span\" {...{\n                                  \"className\": \"mord mathdefault mtight\"\n                                }}>{`x`}</span></span></span></span><span parentName=\"span\" {...{\n                            \"style\": {\n                              \"top\": \"-3.23em\"\n                            }\n                          }}><span parentName=\"span\" {...{\n                              \"className\": \"pstrut\",\n                              \"style\": {\n                                \"height\": \"3em\"\n                              }\n                            }}></span><span parentName=\"span\" {...{\n                              \"className\": \"frac-line\",\n                              \"style\": {\n                                \"borderBottomWidth\": \"0.04em\"\n                              }\n                            }}></span></span><span parentName=\"span\" {...{\n                            \"style\": {\n                              \"top\": \"-3.446108em\"\n                            }\n                          }}><span parentName=\"span\" {...{\n                              \"className\": \"pstrut\",\n                              \"style\": {\n                                \"height\": \"3em\"\n                              }\n                            }}></span><span parentName=\"span\" {...{\n                              \"className\": \"sizing reset-size6 size3 mtight\"\n                            }}><span parentName=\"span\" {...{\n                                \"className\": \"mord mtight\"\n                              }}><span parentName=\"span\" {...{\n                                  \"className\": \"mord mathdefault mtight\"\n                                }}>{`d`}</span><span parentName=\"span\" {...{\n                                  \"className\": \"mord text mtight\"\n                                }}><span parentName=\"span\" {...{\n                                    \"className\": \"mord mtight\"\n                                  }}>{`logit`}</span></span></span></span></span></span><span parentName=\"span\" {...{\n                          \"className\": \"vlist-s\"\n                        }}>{`​`}</span></span><span parentName=\"span\" {...{\n                        \"className\": \"vlist-r\"\n                      }}><span parentName=\"span\" {...{\n                          \"className\": \"vlist\",\n                          \"style\": {\n                            \"height\": \"0.345em\"\n                          }\n                        }}><span parentName=\"span\"></span></span></span></span></span><span parentName=\"span\" {...{\n                    \"className\": \"mclose nulldelimiter\"\n                  }}></span></span><span parentName=\"span\" {...{\n                  \"className\": \"mspace\",\n                  \"style\": {\n                    \"marginRight\": \"0.2222222222222222em\"\n                  }\n                }}></span><span parentName=\"span\" {...{\n                  \"className\": \"mbin\"\n                }}>{`∗`}</span><span parentName=\"span\" {...{\n                  \"className\": \"mspace\",\n                  \"style\": {\n                    \"marginRight\": \"0.2222222222222222em\"\n                  }\n                }}></span></span><span parentName=\"span\" {...{\n                \"className\": \"base\"\n              }}><span parentName=\"span\" {...{\n                  \"className\": \"strut\",\n                  \"style\": {\n                    \"height\": \"1em\",\n                    \"verticalAlign\": \"-0.25em\"\n                  }\n                }}></span><span parentName=\"span\" {...{\n                  \"className\": \"mord mathdefault\"\n                }}>{`p`}</span><span parentName=\"span\" {...{\n                  \"className\": \"mopen\"\n                }}>{`(`}</span><span parentName=\"span\" {...{\n                  \"className\": \"mord mathdefault\"\n                }}>{`x`}</span><span parentName=\"span\" {...{\n                  \"className\": \"mclose\"\n                }}>{`)`}</span></span></span></span></span>{`.`}</d-footnote>{` `}</p>\n    <HumanLabels active=\"expectedValue\" yAxisProps={{\n      label: \"Contribution to Expected Value\"\n    }} stackProps={{\n      domain: {\n        y: [0, 0.1]\n      }\n    }} caption=\"Contribution to the expected value of different activations, which shows how much each activation value influences the output of a neuron. Since curves are rare within the dataset, weak neuron activations contribute most to expected value..\" data={require('./data/human-ev.json')} mdxType=\"HumanLabels\" />\n    <p>{`When we looked at probability density earlier, one might have been skeptical that `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` was really a curve detector in a meaningful sense. Even if it's highly selective when it fires strongly, how can that be what matters when it isn't even visible on a probability density plot? Contribution to expected value shows us that even by a conservative measure, curves and imperfect curves form 55%. This seems consistent with the hypothesis that it really is a curve detector, and the other stimuli causing it to fire are labeling errors or noise.`}</p>\n    <p>{`Our experiments studying the dataset so far has shown us that `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{` activations seem to correspond roughly to a human labelled judgement of whether images contain curves. Additionally, visualizing the attribution vector of these images tells us that the reason these images fire is because of the curves in the images, and we're not being fooled by spurious correlations. But these experiments are not enough to defend the claim that curve neurons detect images of curves. Since images of curves appear infrequently in the dataset, using it to systematically study curve images is difficult. Our next few experiments will focus on this directly, studying how curve neurons respond to the space of reasonable curve images.`}</p>\n    <H2 mdxType=\"H2\">Joint Tuning Curves</H2>\n    <p>{`Our first two experiments suggest that each curve detector responds to curves at a different orientation. Our next experiment will help verify that they really do detect rotated versions of the same feature, and characterize how sensitive each unit is to changes in orientation.`}</p>\n    <p>{`We do this by creating a `}<strong parentName=\"p\">{`joint tuning curve`}</strong><d-footnote>{`In neuroscience, tuning curves — graphs of neural response to a continuous stimulus parameter — came to prominence in the early days of vision research. Observation of receptive fields and orientation-specific responses in neurons gave rise to some of the earliest theories about how low-level visual features might combine to create higher-level representations. Since then they have been a mainstay technique in the field.`}</d-footnote>{` of how all curve detectors respond if we rotate natural dataset examples that caused a particular curve detector to fire.`}</p>\n    <p>{`Each neuron has a gaussian-like bump surrounding it's preferred orientation, and as\neach one stops firing another starts fire, jointly spanning all orientations of curves.`}</p>\n\n    <Tuning mdxType=\"Tuning\" />\n    <p>{`While tuning curves are useful for measuring neuron activations across perturbations in natural images, we're limited by the kinds of perturbations we can do on these images. In our next experiment we'll get access to a larger range of perturbations by synthesizing stimuli from scratch.`}</p>\n    <H2 mdxType=\"H2\">Synthetic Curves</H2>\n    <p>{`While the dataset gives us almost every imaginable curve, they don't come labelled with data such as orientation or radius, making it hard to answer questions that require systematically measuring responses to visual properties. How sensitive are curve detectors to curvature? What orientations do they respond to? Does it matter what colors are involved? One way to get more insight into these questions is to draw our own curves. Using synthetic stimuli like this is a common method in visual neuroscience, and we've found it to also be very helpful in the study of artificial neural networks. The experiments in this section are specifically inspired by similar experiments probing for curve detecting biological neurons `}<d-cite bibtex-key=\"pasupathy1999responses,Jiang808907\"></d-cite>{`.`}</p>\n    <p>{`Since dataset examples suggest curve detectors are most sensitive to orientation and curvature, we'll use them as parameters in our curve renderer. We then see how much each stimuli causes a given neuron, such as `}<Neuron layer=\"mixed3b\" neuron={379} mdxType=\"Neuron\" />{`, to fire. We find it helpful to present this as a heatmap, in order to get a higher resolution perspective on what causes the neuron to fire.`}</p>\n\n    <SyntheticIntro mdxType=\"SyntheticIntro\" />\n    <p>{`We find that simple drawings can be extraordinarily exciting. The curve images that cause the strongest excitations — up to 24 standard deviations above the average dataset activation! — have similar orientation and curvature to the neuron's feature visualization.`}</p>\n\n    <SyntheticMain mdxType=\"SyntheticMain\" />\n    <p>{`Why do we see wispy triangles?`}</p>\n    <p>{`The triangular geometry shows that curve detectors respond to a wider range of orientations in curves with higher curvature. This is because curves with more curvature contain more orientations. Consider that a line contains no curve orientations while a circle contains every curve orientation. Since the synthetic images closer to the top are closer to lines, their activations are more narrow.`}</p>\n    <p>{`The wisps show that tiny changes in orientation or curvature can cause dramatic changes in activations, which means that curve detectors are fragile and non-robust. Sadly, this is a more general problem across neuron families, and we see it as early as the `}<a href=\"https://distill.pub/2020/circuits/early-vision/#group_conv2d1_complex_gabor\">{`Complex Gabor family`}</a>{` in the second layer (`}<a href=\"https://microscope.openai.com/models/inceptionv1/conv2d1_0\">{`conv2d1`}</a>{`).`}</p>\n    <p>{`Varying curves along just two variables reveals barely-perceptible perturbations that sway activations several standard deviations. This suggests that the higher dimensional pixel-space contains more pernicious exploits. We're excited about the research direction of carefully studying neuron-specific adversarial attacks. It's tractible to follow the whole circuit leading from the input of a neural network to any neuron in early vision, and this could be made simpler by extracting the important parts of a circuit and studying it in isolation. Perhaps this simplified environment could give us clues into how to defend neurons and one day whole models against adversarial attacks.`}</p>\n    <p>{`In addition to testing orientation and curvature, we can also test other properties like fill and color. Dataset analyses hints that curve detectors are invariant to cosmetic properties like lighting and color, and we can confirm this with synthetic stimuli. We can also look at pre-ReLU activations, which shows that curve detectors are generally inhibited by curves that don't excite them.`}</p>\n\n    <SyntheticCosmetic mdxType=\"SyntheticCosmetic\" />\n    <H2 mdxType=\"H2\">Synthetic Angles</H2>\n    <p>{`Both our synthetic curve experiments and dataset analysis show that although curves are sensitive to orientation, they have a wide tolerance for the radius of curves. At the extreme, curve neurons partially respond to edges in a narrow band of orientations, which can be seen as a curve with infinite radius. This may cause us to think curve neurons actually respond to shape orientation, rather than curves specifically. While we cannot systematically render all possible shapes to understand this fully, we think angles are a good test case for studying this hypothesis.`}</p>\n    <p>{`In the following experiment we vary synthetic angles similarly to our synthetic curves, with radius on the y axis and orientation across the x axis.`}</p>\n\n    <Angle1 mdxType=\"Angle1\" />\n    <p>{`The activations form two distinct lines with the strongest activations where they touch. The place where the two lines touch is where the angle is most similar to a curve with an orientation that matches the neuron's feature visualization. Each of the lines in the activations are places where one of the two lines in the angle align with the tangent of the curve. The weaker activations on the right side of the activations have the same cause, but with the inhibitory half of the angle stimulus facing outwards instead of inwards. `}</p>\n\n    <AngleZoomIn mdxType=\"AngleZoomIn\" />\n    <p>{`The first stimulus we tested was curves and the second was angles. In the next example we visualize the intermediary states connecting these stimuli, starting with angles, then angles with beveled corners, and ending with the first curve stimulus we tested. Each column's strongest activation is stronger than the column before it, reflecting that rounder stimuli cause stronger activations. Additionally, each “triangle\" becomes more filled as the two lines forming the original angle transitions into a single arc.`}</p>\n\n    <ToCurves mdxType=\"ToCurves\" />\n    <p>{`Seeing how curve detectors respond to synthetic stimuli is useful but the interface we've been using is bulky. For our experiments later comparing curve families across models, and in the third part of the curve series, across models, we'll need a more compact view of activations. For this, we will use a `}<strong parentName=\"p\">{`radial tuning curve`}</strong>{`.`}</p>\n    <H2 mdxType=\"H2\">Radial Tuning Curve</H2>\n\n    <Radial data={require('./data/curves-mixed3b.json')} mdxType=\"Radial\" />\n    <H2 mdxType=\"H2\">The Curve Families of InceptionV1</H2>\n    <p>{`So far we've been looking at a set of curve neurons in 3b. But InceptionV1 actually contains curve neurons in four contiguous layers, with 3b being the third of these layers.`}</p>\n\n    <FamiliesModel mdxType=\"FamiliesModel\" />\n    <H3 mdxType=\"H3\">conv2d2</H3>\n    <p>{`“conv2d2\", which we sometimes shorten to \"2\", is the third convolutional layer in InceptionV1. It contains two types of curve detectors: concentric curves and combed edges.`}</p>\n    <p>{`Concentric curves are small curve detectors that have a preference for seeing multiple curves at the same orientation but of increasing radii. This feature may have an important role in the development of curve detectors in 3a and 3b that are tolerant of a wide range of radii.`}</p>\n    <img width={703} style={{\n      transform: \"translateX(-7px)\",\n      marginTop: 5,\n      marginBottom: 20\n    }} src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fnick-personal%2F1XjsJAYh6F.png?alt=media&token=5b85d1d5-2692-49c9-8976-31dd4f3b1d6b\" />\t\t\t\t\n    <p>{`Combed edges detect several lines protruding perpendicularly from a larger line. These protruding lines also detect curves, making them a type of curve detector. These neurons are used to construct later curve detectors and play a part in the `}<a parentName=\"p\" {...{\n        \"href\": \"#combing-effect\"\n      }}>{`combing effect`}</a>{`.`}</p>\n    <p>{`Looking at conv2d2 activations we see that curves respond to one contiguous range like the ones we've been studying, but they also respond to another range 180 degrees away more weakly. We call this secondary firing `}<strong parentName=\"p\">{`echoes`}</strong>{`.`}</p>\n\n    <RadialLayer data={require(\"./data/curves-conv2d2.json\")} mdxType=\"RadialLayer\" />\n    <H3 mdxType=\"H3\">3a</H3>\n    <p>{`By 3a non-concentric curve detectors have formed. In many ways they resemble the curve detectors in 3b, and in the next article we'll see how they're used to build them. One difference is that the 3a curves have echoes.`}</p>\n    <RadialLayer data={require(\"./data/curves-mixed3a.json\")} mdxType=\"RadialLayer\" />\n    <H3 mdxType=\"H3\">3b</H3>\n    <p>{`These are the curve detectors we've been focusing on in this article. They have clean activations with no echoes.`}</p>\n    <p>{`You may notice that there are two large angular gaps at the top of the radial tuning curve for 3b, and smaller ones at the bottom. Why is that? One factor is that the model also has what we call `}<a href=\"https://distill.pub/2020/circuits/early-vision/#group_mixed3b_double_curves\">{`double curve detectors`}</a>{` which respond to curves in two different orientations and help fill in the gaps.`}</p>\n    <RadialLayer data={require(\"./data/curves-mixed3b.json\")} mdxType=\"RadialLayer\" />\n    <H3 mdxType=\"H3\">4a</H3>\n    <p>{`Layer 4a is where the network constructs many complex shapes such as spirals and boundary detectors, and it is also the first layer to construct 3d geometry. It has several curve detectors, but we believe they are better thought of as corresponding to specific worldly objects rather than abstract shapes. Many of these curves are found in 4a's `}<a parentName=\"p\" {...{\n        \"href\": \"https://microscope.openai.com/models/inceptionv1/mixed4a_5x5_0\"\n      }}>{`5x5 branch`}</a>{`, which seems to specialize in 3d geometry.`}</p>\n    <p>{`For instance, `}<Neuron layer=\"mixed4a\" neuron={406} mdxType=\"Neuron\" />{` appears to be a upwards facing curve detector with confusing secondary behavior at two other angles. But dataset examples reveal its secret: it's detecting the tops of cups and pans viewed from an angle. In this sense, it is better viewed as a tilted 3d circle detector.`}</p>\n\n    <Highlight4a406 mdxType=\"Highlight4a406\" />\n    <p>{`We think `}<Neuron layer=\"mixed4a\" neuron={406} mdxType=\"Neuron\" />{` is a good example of the subjective nature of neural network interpretability. We usually think of abstract concepts like curves and worldly objects like coffee cups as belonging as different categories of things — and for most of the network they are. But there's a transition period where we have to make a judgement call, and 4a is that transition.`}</p>\n    <RadialLayer data={require(\"./data/curves-mixed4a.json\")} mdxType=\"RadialLayer\" />\n    <H2 mdxType=\"H2\">Repurposing Curve Detectors</H2>\n    <p>{`We started studying curve neurons to better understand neural networks, not because we were intrinsically interested in curves. But during our investigation we became aware that curve detection is important for fields like aerial imaging, self-driving cars, and medical research, and there's a breadth of literature from classical computer vision on curve detection in each domain. We've prototyped a technique that leverages the curve neuron family to do a couple different curve related computer vision tasks.`}</p>\n    <p>{`One task is curve extraction `}<d-cite bibtex-key=\"raghupathy2004curve\"></d-cite>{` , the task of  highlighting the pixels of the image that are part of curves. Visualizing attribution to curve neurons, as we've been doing in this article, can be seen as a form of curve extraction. Here we compare it to the commonly used Canny edge detection algorithm on an x-ray of blood vessels known as an angiogram. `}</p>\n\n    <Extraction mdxType=\"Extraction\" />\n    <p>{`The attribution visualization clearly separates and illuminates the lines and curves, and displays less visual artifacts. However, it displays a strong `}<a parentName=\"p\" {...{\n        \"href\": \"#combing-effect\"\n      }}>{`combing effect`}</a>{` `}{`—`}{` unwanted perpendicular lines emanating from the edge being traced. We're unsure how harmful these lines are in practice, but we think it's possible to remove them by editing the circuits of curve neurons.`}</p>\n    <p>{`We don't think we've created the new leading curve tracing technique. Indeed, our goal is not to do  a detailed comparison between attribution visualization and state of the art curve extraction techniques `}{`—`}{` we believe it's likely that classical algorithms tuned for precisely this goal outperform this approach. Instead, our goal here is to explore how leveraging internal neural network representations opens up a vast space of visual operations, of which curve extraction is just one point.`}</p>\n    <H3 mdxType=\"H3\">Spline Parameterization</H3>\n    <p>{`We can access more parts of this space by changing what we optimize. So far we've been optimizing pixels, but we can also create a differentiable parameterization `}<d-cite bibtex-key=\"mordvintsev2018differentiable\"></d-cite>{` that renders curves, similar to explorations by `}<d-cite bibtex-key=\"synthetic\"></d-cite>{` and `}<d-cite bibtex-key=\"nakano2019neural\"></d-cite>{`. By backpropagating from the attribution through the input into spline knots, we can now trace curves `}{`—`}{` obtaining the equations of the best fitting spline equations that describe the curves in the image. `}</p>\n\n    <DiffParams mdxType=\"DiffParams\" />\n    <p>{`We created an early prototype of this approach. Since curve neurons work in a variety of settings`}<d-footnote>{`As we explored in the article, curve neurons are robust to cosmetic properties like brightness and texture.`}</d-footnote>{`, our spline parameterization does too.`}</p>\n\n    <Tracing mdxType=\"Tracing\" />\n    <H3 mdxType=\"H3\">Algorithmic Composition</H3>\n    <p>{`One seemingly unrelated visual operation is image segmentation. `}<d-cite bibtex-key=\"synthetic\"></d-cite>{` and `}<d-cite bibtex-key=\"olah2018building\"></d-cite>{` demonstrates how this can be done in an unsupervised way with non-negative matrix factorization (NMF). We can compose this factorization with the spline parameterization to trace the curves of different objects in the image.`}</p>\n\n    <Butterfly mdxType=\"Butterfly\" />\n    <p>{`Instead of factoring the activations of a single image, we can jointly factorize lots of butterflies to find the neurons in the network that respond to butterflies in general. One big difference between factoring activations and normal image segmentation is that we get groups of neurons rather than pixels. By composing these neurons with a differentiable spline parameterization we get a single optimization we can apply to any image that automatically finds butterflies and gives us equations to splines that fit them.`}</p>\n\n    <ButterflyQuilt mdxType=\"ButterflyQuilt\" />\n    <p>{`In this above example we manipulated butterflies and curves without having to worry about the details of either. We delegated the intricacies of recognizing butterflies of many species and orientations to the neurons, letting us work with the abstract concept of butterflies. `}</p>\n    <p>{`We think this is one exciting way to fuse classical computer vision with deep learning. There is plenty of low hanging fruit in extending the technique shown above, as our spline parameterization is just an early prototype and using a neural network that's half a decade old. However, we're more excited by investigations of how users can explore the space between tasks than improvements in any particular task. Once a task is set in stone, training a neural network for exactly that job will likely give the best results. But real world tasks are rarely specified with precision, and the harder challenge is to explore the space of tasks to find which to commit to.`}</p>\n    <p>{`For instance, a more developed version of our algorithm that automatically finds the splines of butterflies in an image could be used as a basis for turning video footage of butterflies into an animation`}<d-footnote>{`Using a shared parameterization to maintain consistency between frames`}</d-footnote>{`. But the animator may wish to add texture neurons and change to a soft brush parameterization to add a rotoscoping style to their animation. Since they have full access to every neuron, they may be able to manipulate attribution to fur neuron families and specific dog breeds, changing how fur is rendered on specific species of dogs across the entire movie. Since none of these algorithms require retraining a neural network or any training data, the animator could explore this space of algorithms in nearly real time, which is important because tight feedback loops can be crucial in unlocking creative potential.`}</p>\n    <H2 mdxType=\"H2\">The Combing Phenomenon</H2>\n    <p>{`One curious aspect of curve detectors is that they seem to be excited by small lines perpendicular to the curve, both inwards and outwards. You can see this most easily by inspecting feature visualizations. We call this phenomenon \"combing.\"`}</p>\n    <p>{`Combing seems to occur across curve detectors from many models, including models trained on Places365 instead of ImageNet. In fact, there's some weak evidence it occurs in biological neural networks as well: a team that ran a process similar to feature visualization on a biological neuron in a Macaque monkey's V4 region of the visual cortex found a circular shape with outwardly protruding lines to be one of the highest activating stimuli`}<d-cite bibtex-key=\"tang2018complex\"></d-cite>{` , Supplementary Figure A & F.`}</p>\n\n    <CombingEffect mdxType=\"CombingEffect\" />\n    <p>{`A number of potential explanations for combing have been proposed, with no clear forerunner.`}</p>\n    <p>{`One hypothesis is that many important curves in the modern world have perpendicular lines, such as the spokes of a wheel or the markings on the rim of a clock.`}</p>\n\n    <CombingDataset data={require('./data/angle-attribution.json')} mdxType=\"CombingDataset\" />\n    <p>{`A related hypothesis that combing might allow curve detectors to be used for fur detection in some contexts.\nAnother hypothesis is that a curve has higher \"contrast\" it exists despite perpendicular lines running towards it.`}</p>\n    <p>{`Finally, it's been suggested that combing is really a result of a convenient way to implement curve detectors `}{`—`}{` a side effect of a convenient shortcut in creating a circuit rather than being a useful feature intrinsically. We know that in the second conv layer, edge detectors are inhibited by perpendicular lines. We also think that an important part of creating true line or curve detectors is making features that prefer a single strong line to a repeating texture, and that seems to be done by weakly inhibiting in response to parallel lines beside the primary edge. Being excited by a perpendicular line may be an easy way to implement a \"inhibit an excitatory neuron\" pattern which allows for capped inhibition, without creating dedicated neurons at the previous layer. `}</p>\n    <p>{`Combing is not unique to curves. We also observe it in edges, and basically any shape feature like curves that is derivative of edges. A lot more work could be done exploring the combing phenomenon. Why does combing form? Does it persist in adversarially robust models? Is it an example of what Ilyas et al `}<d-cite bibtex-key=\"ilyas2019adversarial\"></d-cite>{` call a \"non-robust feature\"? `}</p>\n    <H2 mdxType=\"H2\">Conclusion</H2>\n    <p>{`Compared to fields like neuroscience, artificial neural networks make careful investigation easy. We can read and write to every weight in the neural network, use gradients to optimize stimuli, and analyze billions of realistic activations across a dataset. Composing these tools lets us run a wide range of experiments that show us different perspectives on a neuron. If every perspective shows the same story, it's unlikely we're missing something big. `}</p>\n    <p>{`Given this, it may seem odd to invest so much energy into just a handful of neurons. We agree. We first estimated it would take a week to understand the curve family. Instead, we spent months exploring the fractal of beauty and structure we found.`}</p>\n    <p>{`Many paths led to new techniques for studying neurons in general, like synthetic stimuli or using circuit editing to ablate neurons behavior. Others are only relevant for some families, such as the equivariance motif or our hand-trained “artificial artificial neural network\" that reimplements curve detectors. A couple were curve-specific, like exploring curve detectors as a type of finding a new class of curve analysis algorithms.`}</p>\n    <p>{`It may seem concerning that it took so much effort to understand\nIf our broader goal is fully reverse-engineer neural networks it may seem concerning that studying just one family took so much effort. However, from our experience studying neuron families at a variety of depths, we've found that it's easy to understand the basics of a neuron family. `}<a href=\"https://microscope.openai.com/models\">{`OpenAI Microscope`}</a>{` can show you feature visualization, dataset examples, and soon weights in just a few seconds, and as we'll discuss in this article, these are collectively strong evidence of what a neuron does. In fact, we understood the basics of curves at our first glance at them. `}</p>\n    <p>{`At the same time, researchers engaging in closer inquiry of neuron families will be rewarded with deeper beauty. We never found an end to the fractal of studying the curve family. We didn't fuse classical curve analysis with deep learning or extract the curve circuit as a microcosm for understanding adversarial attacks, for example. `}</p>\n    <p>{`When we started, we were nervous that 10 neurons was too narrow a topic for a paper, but now we realize a complete investigation would take a book.`}</p>\n    <PrevNext mdxType=\"PrevNext\" />\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAHA;AACA;AAIA;AAGA;AACA;AAGA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAFA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAFA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AACA;AACA;AACA;AAHA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAFA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAFA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AACA;AACA;AACA;AAHA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAEA;AAAA;AAAA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AADA;AAEA;AAAA;AAAA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAFA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAFA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAFA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAFA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AACA;AADA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AADA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AACA;AADA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AADA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAFA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AACA;AADA;AAEA;AACA;AACA;AADA;AADA;AAIA;AAAA;AAAA;AANA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AACA;AACA;AAHA;AAIA;AAJA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAEA;AACA;;;;A","sourceRoot":""}